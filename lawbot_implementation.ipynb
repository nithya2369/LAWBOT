{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b48f11",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-community\n",
    "!pip install langchain-groq\n",
    "!pip install langchain-core\n",
    "!pip install gpt4all\n",
    "!pip install langgraph==0.3.1\n",
    "# !pip install chromadb\n",
    "!pip install sentence-transformers\n",
    "!pip install tavily-python\n",
    "!pip install gradio\n",
    "!pip install langchain-huggingface\n",
    "!pip install pypdf\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c12ba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders.web_base import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import nest_asyncio\n",
    "# from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "# from pydantic import BaseModel, Field\n",
    "from langchain_core.pydantic_v1 import BaseModel,Field\n",
    "from typing import Literal\n",
    "from langchain.chains.combine_documents import stuff\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from IPython.core.display import Markdown\n",
    "import json\n",
    "import re\n",
    "from langchain_core.runnables import (\n",
    "    RunnableParallel,\n",
    "    RunnableBranch,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from operator import itemgetter\n",
    "import asyncio\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9486a2a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "# loading variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "# accessing and printing value\n",
    "GROQ_API_KEY = userdata.get(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY = userdata.get(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT = userdata.get(\"LANGCHAIN_PROJECT\")\n",
    "TAVILY_API_KEY = userdata.get(\"TAVILY_API_KEY\")\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"Agentic RAG\"\n",
    "os.environ[\"TAVILY_API_KEY\"]=TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbef213",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3097141b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def parse_search_research(results: str):\n",
    "    pattern = r\"\\[content: (.*?), title: (.*?), url: (.*?)\\]\"\n",
    "    result = re.findall(pattern, results)\n",
    "\n",
    "    data_list = []\n",
    "    for snippet, title, link in result:\n",
    "        data_list.append({\"content\": snippet, \"title\": title, \"url\": link})\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f06c56",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load FAISS index from disk\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "faiss_folder = \"/content/drive/MyDrive/faiss_index/faiss_index\"\n",
    "faiss_index_path = os.path.join(faiss_folder, \"faiss_index\")\n",
    "\n",
    "embedding_function = HuggingFaceEmbeddings(show_progress=True, multi_process=True)\n",
    "vector_store = FAISS.load_local(faiss_index_path, embedding_function, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Define retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1625cf0c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class VectorStore(BaseModel):\n",
    "    (\n",
    "        \"A vectorstore contains information about corporate laws, \"\n",
    "        \"rules, and regulations related to companies, startups, compliance, \"\n",
    "        \"director responsibilities, shareholder rights, taxation, and other \"\n",
    "        \"corporate legal aspects.\"\n",
    "    )\n",
    "\n",
    "    query: str\n",
    "\n",
    "\n",
    "class SearchEngine(BaseModel):\n",
    "    \"\"\"A search engine for searching other corporate legal information on the web\"\"\"\n",
    "\n",
    "    query: str\n",
    "\n",
    "class SearchEngine(BaseModel):\n",
    "    \"\"\"A search engine for searching other medical information on the web\"\"\"\n",
    "\n",
    "    query: str\n",
    "\n",
    "router_prompt_template = (\n",
    "    \"You are an expert in routing user queries to either a VectorStore or a SearchEngine.\\n\"\n",
    "    \"Use SearchEngine for all other corporate law-related queries that are not already present in the VectorStore or any quesry which demands latest updates.\\n\"\n",
    "    \"The VectorStore contains information on corporate laws, compliance, company formation, director duties, \"\n",
    "    \"shareholder rights, and taxation.\\n\"\n",
    "    'Note that if a query is not related to corporate laws, you must output \"not corporate law-related\", '\n",
    "    \"don't try to use any tool.\\n\\n\"\n",
    "    \"State the answers according to Indian laws only\"\n",
    "    \"query: {query}\"\n",
    ")\n",
    "\n",
    "llm = ChatGroq(model=\"Llama3-70b-8192\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_template(router_prompt_template)\n",
    "question_router = prompt | llm.bind_tools(tools=[VectorStore, SearchEngine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc07d85",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import validator\n",
    "\n",
    "\n",
    "class Grader(BaseModel):\n",
    "    \"Use this format to give a binary score for relevance check on retrived documents.\"\n",
    "\n",
    "    grade: Literal[\"relevant\", \"irrelevant\"] = Field(\n",
    "        ...,\n",
    "        description=\"The relevance score for the document.\\n\"\n",
    "        \"Set this to 'relevant' if the given context is relevant to the user's query, or 'irrlevant' if the document is not relevant.\",\n",
    "    )\n",
    "\n",
    "    @validator(\"grade\", pre=True)\n",
    "    def validate_grade(cls, value):\n",
    "        if value == \"not relevant\":\n",
    "            return \"irrelevant\"\n",
    "        return value\n",
    "\n",
    "\n",
    "grader_system_prompt_template = \"\"\"\"You are a grader tasked with assessing the relevance of a given context to a query.\n",
    "    If the context is relevant to the query, score it as \"relevant\". Otherwise, give \"irrelevant\".\n",
    "    Do not answer the actual answer, just provide the grade in JSON format with \"grade\" as the key, without any additional explanation.\"\n",
    "    \"\"\"\n",
    "\n",
    "grader_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", grader_system_prompt_template),\n",
    "        (\"human\", \"context: {context}\\n\\nquery: {query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "grader_chain = grader_prompt | llm.with_structured_output(Grader, method=\"json_mode\")\n",
    "\n",
    "# query = \"Importance of Corporate laws\"\n",
    "# context =vector_store.similarity_search(query)\n",
    "\n",
    "# response = grader_chain.invoke({\"query\": query, \"context\": context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cbc4a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rag_template_str = (\n",
    "    \"You are a helpful assistant. Answer the query below based only on the provided context. You are an expert in answering queries answer in a good manner like a professional\\n\\n\"\n",
    "    \"Do not give answers like 'as evident from the page content of the first document' that is, do not say that you are giving answer from documents\"\n",
    "    \"also dont mention their addresses like this '(id='50db2a45-2acc-44a9-9199-f754961e852b')'\"\n",
    "    \"context: {context}\\n\\n\"\n",
    "    \"query: {query}\"\n",
    ")\n",
    "\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template_str)\n",
    "rag_chain = rag_prompt | llm | StrOutputParser()\n",
    "\n",
    "# query = \"What is the difference between a public limited company and a private limited company?\"\n",
    "# context = vector_store.similarity_search(query)\n",
    "\n",
    "# response = rag_chain.invoke({\"query\": query, \"context\": context})\n",
    "\n",
    "# Markdown(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa6468",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fallback_prompt = ChatPromptTemplate.from_template(\n",
    "    (\n",
    "        \"You are a friendly legal assistant created by JuridiCo.\\n\"\n",
    "        \"Do not respond to queries that are not related to corporate law.\\n\"\n",
    "        \"If a query is not related to law, acknowledge your limitations.\\n\"\n",
    "        \"Provide concise responses to only legally-related queries.\\n\\n\"\n",
    "        \"Current conversations:\\n\\n{chat_history}\\n\\n\"\n",
    "        \"human: {query}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fallback_chain = (\n",
    "    {\n",
    "        \"chat_history\": lambda x: \"\\n\".join(\n",
    "            [\n",
    "                (\n",
    "                    f\"human: {msg.content}\"\n",
    "                    if isinstance(msg, HumanMessage)\n",
    "                    else f\"AI: {msg.content}\"\n",
    "                )\n",
    "                for msg in x[\"chat_history\"]\n",
    "            ]\n",
    "        ),\n",
    "        \"query\": itemgetter(\"query\") ,\n",
    "    }\n",
    "    | fallback_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "fallback_chain.invoke(\n",
    "    {\n",
    "        \"query\": \"Hello\",\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681257a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class HallucinationGrader(BaseModel):\n",
    "    \"Binary score for hallucination check in llm's response\"\n",
    "\n",
    "    grade: Literal[\"yes\", \"no\"] = Field(\n",
    "        ..., description=\"'yes' if the llm's reponse is hallucinated otherwise 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "hallucination_grader_system_prompt_template = (\n",
    "    \"You are a grader assessing whether a response from an llm is based on a given context.\\n\"\n",
    "    \"If the llm's response is not based on the given context give a score of 'yes' meaning it's a hallucination\"\n",
    "    \"otherwise give 'no'\\n\"\n",
    "    \"Just give the grade in json with 'grade' as a key and a binary value of 'yes' or 'no' without additional explanation\"\n",
    ")\n",
    "\n",
    "hallucination_grader_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", hallucination_grader_system_prompt_template),\n",
    "        (\"human\", \"context: {context}\\n\\nllm's response: {response}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "hallucination_grader_chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"response\": itemgetter(\"response\"),\n",
    "            \"context\": lambda x: \"\\n\\n\".join([c.page_content for c in x[\"context\"]]),\n",
    "        }\n",
    "    )\n",
    "    | hallucination_grader_prompt\n",
    "    | llm.with_structured_output(HallucinationGrader, method=\"json_mode\")\n",
    ")\n",
    "\n",
    "# query = \"What is the difference between a public limited company and a private limited company?\"\n",
    "# context = retriever.get_relevant_documents(query)\n",
    "# response = \"\"\"Based on the provided context, specifically from page 27 of the \"Companies Act.pdf\" document, the difference between a public limited company and a private limited company lies in the suffix of their names.\n",
    "# A public limited company has the last word \"Limited\" in its name, whereas a private limited company has the last words \"Private Limited\" in its name.\n",
    "# No other differences are explicitly mentioned in the provided context.\n",
    "# \"\"\"\n",
    "\n",
    "# response = hallucination_grader_chain.invoke({\"response\": response, \"context\": context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5430e9bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class AnswerGrader(BaseModel):\n",
    "    \"Binary score for an answer check based on a query.\"\n",
    "\n",
    "    grade: Literal[\"yes\", \"no\"] = Field(\n",
    "        ...,\n",
    "        description=\"'yes' if the provided answer is an actual answer to the query otherwise 'no'\",\n",
    "    )\n",
    "\n",
    "\n",
    "answer_grader_system_prompt_template = (\n",
    "    \"You are a grader assessing whether a provided answer is in fact an answer to the given query.\\n\"\n",
    "    \"If the provided answer does not answer the query give a score of 'no' otherwise give 'yes'\\n\"\n",
    "    \"Just give the grade in json with 'grade' as a key and a binary value of 'yes' or 'no' without additional explanation\"\n",
    ")\n",
    "\n",
    "answer_grader_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", answer_grader_system_prompt_template),\n",
    "        (\"human\", \"query: {query}\\n\\nanswer: {response}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "answer_grader_chain = answer_grader_prompt | llm.with_structured_output(\n",
    "    AnswerGrader, method=\"json_mode\"\n",
    ")\n",
    "\n",
    "# query = \"What is the difference between a public limited company and a private limited company?\"\n",
    "# # context = retriever.get_relevant_documents(query)\n",
    "# response = \"\"\"Based on the provided context, specifically from page 27 of the \"Companies Act.pdf\" document, the difference between a public limited company and a private limited company lies in the suffix of their names.\n",
    "# A public limited company has the last word \"Limited\" in its name, whereas a private limited company has the last words \"Private Limited\" in its name.\n",
    "# No other differences are explicitly mentioned in the provided context.\"\"\"\n",
    "\n",
    "# response = answer_grader_chain.invoke({\"response\": response, \"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df95eb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "# from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\n",
    "# import langgraph\n",
    "# from langgraph.prebuilt import ToolInvocation, ToolExecutor\n",
    "# from langgraph.prebuilt.tool_node import ToolNode\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "import operator\n",
    "\n",
    "# ddg_search = DuckDuckGoSearchResults()\n",
    "tavily_search = TavilySearchResults()\n",
    "# tool_executor = ToolExecutor(\n",
    "#     tools=[\n",
    "#         Tool(\n",
    "#             name=\"VectorStore\",\n",
    "#             func=retriever.invoke,\n",
    "#             description=\"Useful to search the vector database\",\n",
    "#         ),\n",
    "#         Tool(\n",
    "#             name=\"SearchEngine\", func=tavily_search, description=\"Useful to search the web\"\n",
    "#         ),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "class AgentSate(TypedDict):\n",
    "    \"\"\"The dictionary keeps track of the data required by the various nodes in the graph\"\"\"\n",
    "\n",
    "    query: str\n",
    "    chat_history:list[BaseMessage]\n",
    "    generation: str\n",
    "    documents: list[Document]\n",
    "\n",
    "\n",
    "def retrieve_node(state: dict) -> dict[str, list[Document] | str]:\n",
    "    \"\"\"\n",
    "    Retrieve relevent documents from the vectorstore\n",
    "\n",
    "    query: str\n",
    "\n",
    "    return list[Document]\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "    documents = retriever.invoke(input=query)\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\n",
    "def fallback_node(state: dict):\n",
    "    \"\"\"\n",
    "    Fallback to this node when there is no tool call\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "    chat_history = state[\"chat_history\"]\n",
    "    generation = fallback_chain.invoke({\"query\": query, \"chat_history\": chat_history})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "\n",
    "def filter_documents_node(state: dict):\n",
    "    filtered_docs = list()\n",
    "\n",
    "    query = state[\"query\"]\n",
    "    documents = state[\"documents\"]\n",
    "    for i, doc in enumerate(documents, start=1):\n",
    "        grade = grader_chain.invoke({\"query\": query, \"context\": doc})\n",
    "        if grade.grade == \"relevant\":\n",
    "            print(f\"---CHUCK {i}: RELEVANT---\")\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print(f\"---CHUCK {i}: NOT RELEVANT---\")\n",
    "    return {\"documents\": filtered_docs}\n",
    "\n",
    "\n",
    "def rag_node(state: dict):\n",
    "    query = state[\"query\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    generation = rag_chain.invoke({\"query\": query, \"context\": documents})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "\n",
    "def web_search_node(state: dict):\n",
    "    query = state[\"query\"]\n",
    "    results = tavily_search.invoke(query)\n",
    "    results = parse_search_research(results)\n",
    "    documents = [\n",
    "        Document(page_content=doc[\"content\"], metadata={\"source\": doc[\"url\"]})\n",
    "        for doc in results\n",
    "    ]\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\n",
    "def question_router_node(state: dict):\n",
    "    query = state[\"query\"]\n",
    "    try:\n",
    "        response = question_router.invoke({\"query\": query})\n",
    "    except Exception:\n",
    "        return \"llm_fallback\"\n",
    "\n",
    "    if \"tool_calls\" not in response.additional_kwargs:\n",
    "        print(\"---No tool called---\")\n",
    "        return \"llm_fallback\"\n",
    "\n",
    "    if len(response.additional_kwargs[\"tool_calls\"]) == 0:\n",
    "        raise \"Router could not decide route!\"\n",
    "\n",
    "    route = response.additional_kwargs[\"tool_calls\"][0][\"function\"][\"name\"]\n",
    "    if route == \"VectorStore\":\n",
    "        print(\"---Routing to VectorStore---\")\n",
    "        return \"VectorStore\"\n",
    "    elif route == \"SearchEngine\":\n",
    "        print(\"---Routing to SearchEngine---\")\n",
    "        return \"SearchEngine\"\n",
    "\n",
    "\n",
    "def should_generate(state: dict):\n",
    "    filtered_docs = state[\"documents\"]\n",
    "\n",
    "    if not filtered_docs:\n",
    "        print(\"---All retrived documents not relevant---\")\n",
    "        return \"SearchEngine\"\n",
    "    else:\n",
    "        print(\"---Some retrived documents are relevant---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def hallucination_and_answer_relevance_check(state: dict):\n",
    "    llm_response = state[\"generation\"]\n",
    "    documents = state[\"documents\"]\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    hallucination_grade = hallucination_grader_chain.invoke(\n",
    "        {\"response\": llm_response, \"context\": documents}\n",
    "    )\n",
    "    if hallucination_grade.grade == \"no\":\n",
    "        print(\"---Hallucination check passed---\")\n",
    "        answer_relevance_grade = answer_grader_chain.invoke(\n",
    "            {\"response\": llm_response, \"query\": query}\n",
    "        )\n",
    "        if answer_relevance_grade.grade == \"yes\":\n",
    "            print(\"---Answer is relevant to question---\\n\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---Answer is not relevant to question---\")\n",
    "            return \"not useful\"\n",
    "    print(\"---Hallucination check failed---\")\n",
    "    return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1030ac9c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(AgentSate)\n",
    "workflow.add_node(\"VectorStore\", retrieve_node)\n",
    "workflow.add_node(\"SearchEngine\", web_search_node)\n",
    "workflow.add_node(\"filter_docs\", filter_documents_node)\n",
    "workflow.add_node(\"fallback\", fallback_node)\n",
    "workflow.add_node(\"rag\", rag_node)\n",
    "\n",
    "workflow.set_conditional_entry_point(\n",
    "    question_router_node,\n",
    "    {\n",
    "        \"llm_fallback\": \"fallback\",\n",
    "        \"VectorStore\": \"VectorStore\",\n",
    "        \"SearchEngine\": \"SearchEngine\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"VectorStore\", \"filter_docs\")\n",
    "workflow.add_edge(\"SearchEngine\", \"filter_docs\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"filter_docs\", should_generate, {\"SearchEngine\": \"SearchEngine\", \"generate\": \"rag\"}\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"rag\",\n",
    "    hallucination_and_answer_relevance_check,\n",
    "    {\"useful\": END, \"not useful\": \"SearchEngine\", \"generate\": \"rag\"},\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"fallback\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24771a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "response = app.invoke({\"query\": \"What are the company laws?\", \"chat_history\": []})\n",
    "Markdown(response[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a4c00",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "# ... (Your existing imports and code)\n",
    "\n",
    "def api_calling(prompt, history):\n",
    "    try:\n",
    "        response = app.invoke({\"query\": prompt, \"chat_history\": history})\n",
    "        # Assuming 'generation' key holds the LLM response\n",
    "        return response[\"generation\"]\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"  # Return an error message if needed\n",
    "\n",
    "answer_bot = gr.ChatInterface(\n",
    "    fn=api_calling,\n",
    "    chatbot=gr.Chatbot(height=600),\n",
    "    textbox=gr.Textbox(placeholder=\"Ask me about law!\", container=False, scale=7),\n",
    "    title=\"JuridiCo - Corporate Law Chatbot\",\n",
    "    description=\"Welcome to JuridiCo! Ask a legal question, and the bot will provide you with an AI-generated response and any relevant legal documents.\",\n",
    "    theme=\"soft\",\n",
    "    submit_btn=\"Send\",\n",
    ")\n",
    "\n",
    "answer_bot.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
